<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>CS 559, Fall  2016</title>
  <meta http-equiv="content-type"
 content="text/html; charset=ISO-8859-1">
  <meta content="Philippos Mordohai" name="author">
</head>


<body>

<br>
<table border="0" cellpadding="2" cellspacing="2" width="100%">
<tbody>
<tr>
<td valign="top"><font style="font-family: helvetica,arial,sans-serif;" size="+2"><strong>Philippos Mordohai</strong></font><br>
<font style="font-family: helvetica,arial,sans-serif;" size="+1">Assistant Professor<br>
<a href="http://www.cs.stevens.edu/">Department of Computer Science</a><br>
<a href="http://www.stevens.edu/">Stevens Institute of Technology</a><br>
</font>

<p>Office: Lieb 215
<br>Phone Number: +1 201 216 5611
<br>E-mail: mordohai_at_cs.stevens.edu
</td>

<td valign="top"><font style="font-family: helvetica,arial,sans-serif;" size="+2"><strong>CS 559: Machine Learning: Fundamentals and Applications</strong></font><br><br>
<font style="font-family: helvetica,arial,sans-serif;" size="+2">Fall 2016<br>
</font>

</td>
</tr>
</tbody>
</table>





<font style="font-family: helvetica,arial,sans-serif;" size="+1"><br>
</font><strong></strong></div>
<strong><br>
</strong>
<table style="width: 100%; text-align: left;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td valign="top" width="300"><br><big> <big style="color: rgb(255, 255, 255);">

<span style="font-weight: bold; font-family: times new roman,times,serif;"><a href="../index.html">Homepage</a></span><br><br>

</big></big>
</td>


<td valign="top">

<b>Location</b><br>
McLean 105</b><br><br>

<b>Time</b><br>
Wednesdays 6:15-8:45 PM. <br><br>

<b>Office Hours</b><br>
Tuesday 5-6 and by appointment.<br><br>

<b>Pre-requisites</b><br>
Basic knowledge of probability and statistics. Past experience has shown that students without this background struggle in CS 559. <br>
Basic programming in Matlab, python, C/C++ or Java. This is crucial for the final project which requires the implementation of machine learning techniques. <br><br>


<a href="cs559_f16/CS559_f16_syllabus.pdf"><b>Syllabus</b></a>
<br><br>

<b>Textbooks</b><br>

The primary textbook is the following. I refer to it as <b>Barber</b> in the class outline. <br>
Bayesian Reasoning and Machine Learning<br>
by David Barber<br>
Cambridge University Press, 2012.<br>
It is available online free of charge <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online">here</a>.<br><br>

I will also use the following textbook, which I refer to as <b>HTF</b>.<br>
The Elements of Statistical Learning (2nd edition)<br>
by Trevor Hastie, Robert Tibshirani and Jerome Friedman<br>
Springer, 2009. <br>
This book is available also  free of charge <a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">here</a>.<br><br>

<br><br>
<b>Evaluation</b><br>
<em>Final project (25%)</em><br>
Each student will select a project related to machine learning, which has to be approved by me regarding relevance and feasibility. I will provide pointers and suggestions for potential projects.
Students actively involved in machine learning research can select a project related to their research, but new work has to be done during the semester. Large projects can be performed by
groups of two students. Each student will briefly present his or her project in 3-5 minutes during Week 9. Final project reports and presentations are due in Week 14.<br><br>
<em>Homework assignments (20%)</em><br>
Homework sets will be tentatively assigned in Weeks 3, 5, 9 and 12 and will be due a week later. <br><br>
<em>Pop-up quizzes and participation (10%)</em><br>
A simple quiz will be given at the beginning of each class. <br><br>
<em>Midterm (20%)</em><br>
The midterm is scheduled for Week 7 (October 12). <br><br>
<em>Final (25%)</em><br>
The final will take place during the final exam period and will be cumulative.<br><br>

<b>Resources</b><br><br>

The following links should be useful in case you need to refresh your math or Matlab knowledge.
<ul>
<li>Brief <a href="http://www.seas.upenn.edu/~jadbabai/ESE504/LAreview.pdf">linear algebra review</a> (up to p. 15)</li>
<li>Lecture slides from <a href="http://www.farinhansford.com/books/pla/downloads.html">Practical Linear Algebra: A Geometry Toolbox, Third edition</a> by Gerald Farin and Dianne Hansford</li>
<li><a href="https://cseweb.ucsd.edu/classes/wi12/cse190-c/linear_algebra_review.pdf">Linear algebra review</a> by Tim K. Marks, UCSD.</li>
<li><a href="http://www.autonlab.org/tutorials/prob18.pdf">Probabilistic and Bayesian Analytics</a> by A.W. Moore</li>
<li>Lecture slides from <a href="http://www.mhhe.com/engcs/electrical/papoulis/ippt.mhtml">Probability, Random Variables and Stochastic Processes</a> by Athanasios Papoulis and S. Unnikrishna Pillai</li>
<li><a href="http://jkcray.maths.ul.ie/ms4327/manuals/IntroMatlabGriffiths.pdf">An Introduction to Matlab<a/> by David F. Griffiths</li>
<li><a href="http://home.online.no/~pjacklam/matlab/doc/mtt/doc/mtt.pdf">Matlab array manipulation tips and tricks</a> by Peter J. Acklam</li>
</ul>


<b>Outline</b><br><br>
<b>Week 1:</b> Introduction; Probability theory overview (Barber Ch. 1, 8 and 13)<br>
<a href="cs559_f16/cs559f16_Week1.pdf">Notes pt. 1 (pdf)</a>
<br><br>
<b>Week 2:</b> Linear algebra review; Basic graph concepts; Belief networks  (Notes and Barber Ch. 2 and 3)<br>
<a href="cs559_f16/cs559f16_Week2.pdf">Notes pt. 2 (pdf)</a>
<br><br>
<b>Week 3:</b> Bayesian decision theory; Maximum Likelihood Estimation; Bayesian methods (Barber Ch. 8 and 13 and notes)<br>
<a href="cs559_f16/cs559f16_Week3.pdf">Notes pt. 3 (pdf)</a>
<br>
<a href="cs559_f16/cs559_f16_hw1.pdf"><FONT COLOR=#ff0000>Homework 1 (pdf)</font></a> is due on 9/21.
<br><br>
<b>Week 4:</b> Naive Bayes; Non-parametric techniques (Barber Ch.  8, 10 and 14) <br>
<a href="cs559_f16/cs559f16_Week4.pdf">Notes pt. 4 (pdf)</a>
<br><br>
<b>Week 5:</b> Project proposals; Principal Component Analysis; Eigenfaces (Barber Ch.  15)<br>
<a href="cs559_f16/cs559f16_Week5.pdf">Notes pt. 5 (pdf)</a>
<br>
<a href="cs559_f16/cs559_f16_hw2.pdf"><FONT COLOR=#ff0000>Homework 2 (pdf)</font></a> is due on 10/5.
<br><br>
<b>Week 6:</b> Fisher's Linear Discriminant; Generative and Discriminative Approaches (Barber Ch. 16 and 13)<br>
<a href="cs559_f16/cs559f16_Week6.pdf">Notes pt. 6 (pdf)</a>
<br><br>
<b>Week 7:</b> <b>Midterm</b> <br>
<br><br>
<b>Week 8:</b> Linear regression  (Barber Ch. 17 and notes) <br>
<a href="cs559_f16/cs559f16_Week8.pdf">Notes pt. 8 (pdf)</a>
<br><br>
<b>Week 9:</b>  Logistic regression; Perceptron; Support Vector Machines  (Barber Ch. 17, HTF Ch. 4 and 12 and notes) <br>
<a href="cs559_f16/cs559f16_Week9.pdf">Notes pt. 9 (pdf)</a>
<br>
<a href="cs559_f16/cs559_f16_hw3.pdf"><FONT COLOR=#ff0000>Homework 3 (pdf)</font></a> is due on 11/2.
<br><br>
<b>Week 10:</b> Bagging; Random Forests; Boosting (HTF Ch. 10 and 15 and notes)<br>
<a href="cs559_f16/cs559f16_Week10.pdf">Notes pt. 10 (pdf)</a>
<br><br>
<b>Week 11:</b> Hidden Markov Models (Barber Ch. 23 and notes). <br>
<a href="cs559_f16/cs559f16_Week11.pdf">Notes pt. 11 (pdf)</a>
<br>
<a href="cs559_f16/cs559_f16_hw4.pdf"><FONT COLOR=#ff0000>Homework 4 (pdf)</font></a> is due on 11/28.<br>
<a href="cs559_f16/cs559_f16_progress.pdf"><FONT COLOR=#ff0000>Final Project Progress Report (pdf)</font></a> is due on 11/22.
<br><br>
<b>Week 12:</b> Deep Learning  (Notes) <br>
<a href="cs559_f16/cs559f16_Week12.pdf">Notes pt. 12 (pdf)</a>
<br><br>
<b>Week 13:</b>  Unsupervised Learning; Expectation Maximization (HTF Ch. 14 and Barber Ch. 11) <br>
<a href="cs559_f16/cs559f16_Week13.pdf">Notes pt. 13 (pdf)</a>
<br><br>
<b>Week 14:</b> <b>Project presentations</b><br>
<br><br>
<br>





</td>

    </tr>
    <tr>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
  </tbody>
</table>
<strong><br>
</strong><br>
</body>
</html>
